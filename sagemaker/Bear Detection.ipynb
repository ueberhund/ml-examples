{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sagemaker Bear Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook attempts to do my own job of image classification. This notebook pulls a list of bear photos (categorized as \"polar\", \"brown\" and \"no\") and creates a classification model that can be used to predict what kind of bear (again, \"brown\", \"polar\" or \"no\" bear) is in the photo.\n",
    "\n",
    "This notebook is based off the following sources:\n",
    "\n",
    "[1] https://github.com/awslabs/amazon-sagemaker-examples/blob/master/introduction_to_amazon_algorithms/imageclassification_mscoco_multi_label/Image-classification-multilabel-lst.ipynb\n",
    "\n",
    "[2] https://github.com/aws-samples/aws-deeplens-reinvent-2019-workshops/blob/master/AIM405-Advanced/Lab2/lab2-image-classification.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Begin with setting up some standard stuff to run Sagemaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "role = get_execution_role()\n",
    "print(role)\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "bucket = sess.default_bucket()\n",
    "prefix = 'bear'\n",
    "\n",
    "print('using bucket %s'%bucket)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the image classification training image used for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_image = sagemaker.image_uris.retrieve('image-classification', sess.boto_region_name, \"1\")\n",
    "print (training_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We begin by extracting the open_images_bears.zip file. This file contains a list of different kinds of bears from public image sources. \n",
    "\n",
    "Extract the data and save to the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!conda update --all -y\n",
    "!conda install -c conda-forge pycocotools -y\n",
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "import csv\n",
    "import zipfile\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "ZIP_FILE = './open_images_bears.zip'\n",
    "ERRORS_FILE = 'download-errors.txt'\n",
    "CSV_DIR = './image_csv/'\n",
    "DATA_DIR = './data/'\n",
    "if not os.path.isdir(DATA_DIR):\n",
    "    os.mkdir(DATA_DIR)\n",
    "    \n",
    "with zipfile.ZipFile(ZIP_FILE, 'r') as f:\n",
    "    f.extractall(os.path.expanduser(CSV_DIR))\n",
    "    \n",
    "files = list(filter(lambda x: x.endswith('csv'), os.listdir(CSV_DIR)))\n",
    "\n",
    "f = files[0]\n",
    "with open(CSV_DIR + f, 'r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    records = list(reader)\n",
    "    \n",
    "def download(url, path):\n",
    "    r = requests.get(url, allow_redirects=True)\n",
    "    if len(r.content) < 1024:\n",
    "        raise Exception((path.split('/')[-1]).split('.')[0])\n",
    "    else:\n",
    "        open(path, 'wb').write(r.content)\n",
    "        \n",
    "with open(ERRORS_FILE,'w') as f:\n",
    "    f.write('')\n",
    "for idx,fn in enumerate(files):\n",
    "    print('{}/{} {} is being processed.'.format(idx, len(files), fn))\n",
    "    time.sleep(1)\n",
    "    with open(CSV_DIR + fn, 'r') as f:\n",
    "        reader = csv.reader(f)\n",
    "        records = list(reader)[1:] # no header row\n",
    "    stage = fn.split('-')[0]\n",
    "    lbl = fn.split('-')[1]\n",
    "    dir_path = DATA_DIR + stage\n",
    "    if not os.path.isdir(dir_path):\n",
    "        os.mkdir(dir_path)\n",
    "    dir_path = DATA_DIR + '{}/{}'.format(stage,lbl)\n",
    "    if not os.path.isdir(dir_path):\n",
    "        os.mkdir(dir_path)\n",
    "        \n",
    "    cnt = 0 \n",
    "    for row in tqdm(records):\n",
    "        path = dir_path + '/{}.jpg'.format(row[0])\n",
    "        try:\n",
    "            # If thumnail url is empty, download original url\n",
    "            if not row[13]:\n",
    "                download(row[5], path)\n",
    "            else:\n",
    "                download(row[13], path)\n",
    "        except Exception as e:\n",
    "            with open(ERRORS_FILE,'a') as f:\n",
    "                f.write(e.args[0]+'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now create a data file that contains the image and the category it belongs to. These files will be used as the input data to our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "from pycocotools.coco import COCO\n",
    "import random\n",
    "\n",
    "SEARCH_CRITERION = '**/*.jpg'\n",
    "train_images = glob.glob(os.path.join(DATA_DIR + 'train', SEARCH_CRITERION), recursive=True)\n",
    "val_images = glob.glob(os.path.join(DATA_DIR + 'val', SEARCH_CRITERION), recursive=True)\n",
    "test_images = glob.glob(os.path.join(DATA_DIR + 'test', SEARCH_CRITERION), recursive=True)\n",
    "\n",
    "def create_data_file(image_list, image_type):\n",
    "    with open('image-' + image_type + '.lst', 'w') as fp:\n",
    "        for ind in enumerate(image_list):\n",
    "            image_path = ind[1]\n",
    "            fp.write(str(ind[0]) + '\\t')\n",
    "            if image_path.find('/brown/') > -1:\n",
    "                fp.write('0' + '\\t')\n",
    "            elif image_path.find('/polar/') > -1:\n",
    "                fp.write('1' + '\\t')\n",
    "            else:\n",
    "                fp.write('2' + '\\t')\n",
    "            fp.write(image_path[-20:])\n",
    "            fp.write('\\n')\n",
    "        fp.close()\n",
    "\n",
    "random.shuffle(train_images)\n",
    "random.shuffle(val_images)\n",
    "random.shuffle(test_images)\n",
    "\n",
    "create_data_file(train_images, 'train')\n",
    "create_data_file(val_images, 'val')\n",
    "create_data_file(test_images, 'test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show some sample images to make sure everything looks ok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from IPython.display import Image\n",
    "\n",
    "rand_image = random.randrange(1,len(train_images))\n",
    "print(train_images[rand_image])\n",
    "Image(train_images[rand_image])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Push files to S3 in preparation for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Four channels: train, validation, train_lst, and validation_lst\n",
    "s3train = 's3://{}/{}/train/'.format(bucket, prefix)\n",
    "s3validation = 's3://{}/{}/validation/'.format(bucket, prefix)\n",
    "s3train_lst = 's3://{}/{}/train_lst/'.format(bucket, prefix)\n",
    "s3validation_lst = 's3://{}/{}/validation_lst/'.format(bucket, prefix)\n",
    "\n",
    "# upload the image files to train and validation channels\n",
    "!aws s3 cp ./data/train/brown $s3train --recursive --quiet\n",
    "!aws s3 cp ./data/train/no $s3train --recursive --quiet\n",
    "!aws s3 cp ./data/train/polar $s3train --recursive --quiet\n",
    "!aws s3 cp ./data/val/brown $s3validation --recursive --quiet\n",
    "!aws s3 cp ./data/val/no $s3validation --recursive --quiet\n",
    "!aws s3 cp ./data/val/polar $s3validation --recursive --quiet\n",
    "\n",
    "# upload the lst files to train_lst and validation_lst channels\n",
    "!aws s3 cp image-train.lst $s3train_lst --quiet\n",
    "!aws s3 cp image-val.lst $s3validation_lst --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Begin the training of our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_output_location = 's3://{}/{}/output'.format(bucket, prefix)\n",
    "multilabel_ic = sagemaker.estimator.Estimator(training_image,\n",
    "                                         role, \n",
    "                                         instance_count=1, \n",
    "                                         instance_type='ml.p3.2xlarge',\n",
    "                                         volume_size = 50,\n",
    "                                         max_run = 360000,\n",
    "                                         input_mode= 'File',\n",
    "                                         output_path=s3_output_location,\n",
    "                                         sagemaker_session=sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multilabel_ic.set_hyperparameters(num_layers=50,\n",
    "                             use_pretrained_model=1,\n",
    "                             image_shape = \"3,224,224\",\n",
    "                             num_classes=3,\n",
    "                             mini_batch_size=64,\n",
    "                             epochs=10,\n",
    "                             resize=256,\n",
    "                             learning_rate=0.001,\n",
    "                             num_training_samples=1814,\n",
    "                             use_weighted_loss=1,\n",
    "                             augmentation_type = 'crop_color_transform',\n",
    "                             precision_dtype='float16',\n",
    "                             multi_label=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = sagemaker.inputs.TrainingInput(s3train, distribution='FullyReplicated', \n",
    "                        content_type='application/x-image', s3_data_type='S3Prefix')\n",
    "train_data_lst = sagemaker.inputs.TrainingInput(s3train_lst, distribution='FullyReplicated', \n",
    "                        content_type='application/x-image', s3_data_type='S3Prefix')\n",
    "\n",
    "validation_data = sagemaker.inputs.TrainingInput(s3validation, distribution='FullyReplicated', \n",
    "                        content_type='application/x-image', s3_data_type='S3Prefix')\n",
    "validation_data_lst = sagemaker.inputs.TrainingInput(s3validation_lst, distribution='FullyReplicated', \n",
    "                        content_type='application/x-image', s3_data_type='S3Prefix')\n",
    "\n",
    "data_channels = {'train': train_data, 'validation': validation_data, 'train_lst': train_data_lst, \n",
    "                        'validation_lst': validation_data_lst}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "multilabel_ic.fit(inputs=data_channels, logs=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up an endpoint where we can make inferences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ic_classifier = multilabel_ic.deploy(initial_instance_count = 1, instance_type = 'ml.m4.xlarge')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get a random image from our test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "from IPython.display import Image\n",
    "import json\n",
    "\n",
    "rand_image = random.randrange(1,len(test_images)-1)\n",
    "print(test_images[rand_image])\n",
    "\n",
    "with open(test_images[rand_image], 'rb') as image:\n",
    "    f = image.read()\n",
    "    b = bytearray(f)\n",
    "results = ic_classifier.predict(b, initial_args={'ContentType': 'application/x-image'})\n",
    "\n",
    "prob = json.loads(results)\n",
    "classes = ['Brown Bear', 'Polar Bear', 'No Bear']\n",
    "for idx, val in enumerate(classes):\n",
    "    print('%s:%f '%(classes[idx], prob[idx]), end='')\n",
    "Image(test_images[rand_image])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the model does a pretty good job at predicting the right class. This should give you an idea of how to create an image-based model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean up the endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ic_classifier.delete_endpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
